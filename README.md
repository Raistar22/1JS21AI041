RAG system works by first loading the CSV that contains company data, where each row represents a question or attribute (like “Date of incorporation” or “Human rights score”) and each column represents a company with its corresponding values. It then converts each row into a document that combines the question and all company responses for that attribute, effectively building a textual knowledge base. Next, a SentenceTransformer embedding model converts these documents into numerical vectors that capture their semantic meaning, which are stored in a FAISS vector index for fast similarity search. When you ask a question, the system encodes your query into the same vector space, retrieves the most relevant documents from FAISS, and passes that context along with your question to a Flan-T5 text generation model. The model then reads the retrieved company data and generates a concise answer. Finally, a Gradio UI provides an interactive interface where you can type any query, dynamically adjust retrieval parameters, and view the generated answers — all powered by semantic search and context-aware generation.
